# Introduction

This book describes a solution to how computers can solve problems that humans solve intuitively.

> The solution is to allow computers to learn from experience and understand the world in terms of a hierarchy of concepts, with each concept defined through its relation to simpler concepts.

This hierarchy of concepts enables computers to learn complicated concepts building from simpler ones.

> If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers. For this reason, we call this approach to AI **deep learning**.

One of the key challenges of AI is how to represent subjective, intuitive, or informal knowledge in a way a computer can consume and interpret.

> AI systems need the ability to acquire their own knowledge, by extracting patterns from raw data. This capability is known as **machine learning**.

The Introduction of even simple machine learning algorithms (e.g., logistic regression, naive Bayes) enabled computers to solve problems leveraging knowledge in the real world.

> The performance of these simple machine learning algorithms depends heavily on the representation of the data they are given.

Each piece of information included in the representation of data is referred to as a **feature**.

Some AI tasks can be solved by first designing/engineering the right set of features, then providing these features to a simpler machine learning algorithm.

However, for many tasks, it is difficult to know what features provide the most value towards solving a particular problem.

> One solution to this problem is to use machine learning to discover not only the mapping from representation to output but also the representation itself. This approach is known as **representation learning**.

Learned representations have provenly performed better than manually designed ones.

> When designing features or algorithms for learning features, our goal is usually to separate the **factors of variation** that explain the observed data.

Such factors are often not quantifiable but instead as constructs or abstractions that help us make sense of the variability of the data.

> When it is nearly difficult to obtain representation as to solve the original problem, representation learning does not, at first glance, seem to help us.

> **Deep Learning** solves this central problem in representation learning by introducing representations that are expressed in terms of other, simpler representations.

The quintessential example of a deep learning model is the feedforward deep network. Also referred to as the **multilayer perceptron (MLP)**.

> A multilayer perceptron is just a mathematical function mapping some set of input values to output values.

Traditionally, for a computer to understand the meaning of raw input data, there would have to occur a mapping of raw inputs to defined outputs. Learning or evaluating such a mapping can become insurmountable as complexity increases.

> Deep learning resolves this difficulty by breaking the desired complicated mapping into a series of nested simple mappings, each described by a different layer of the model. The input is presented at the **visible layer**, so named because it contains the variables that we able to observe. Then a series of **hidden layers** extract increasingly abstract features from the image. These layers are called *"hidden"* because their values are not given in the data, instead, the model must determine which concepts are useful for explaining the relationships in the observed data.

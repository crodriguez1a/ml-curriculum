# Probability and Information Theory

## Introduction

Probability Theory is a mathematical framework for representing uncertainty.

> It provides a means of quantifying uncertainty as well as axioms for deriving new uncertain statements.

In AI applications, probability theory is used in two major ways. First, the laws of probability tell us how systems should reason.

Second, we use probability and statistics to analyze behavior of proposed AI systems.

> While probability theory allows us to make uncertain statements and to reason in the presence of uncertainty, information theory enables us to quantify the amount of uncertainty in a probability distribution.

## 3.1 Why Probability?

Machine learning will always deal with uncertain quantities and sometimes stochastic (nondeterministic) quantities.

There are three possible sources of uncertainty:

1. Inherent stochasticity
1. Incomplete observability
1. Incomplete modeling

Probability related directly to the rates at which events occur is known as **frequentist probability**. Probability related to quantitative levels of certainty is know as **Bayesian probability**.

> Probability can be seen as the extension of logic to deal with uncertainty. Logic provides a set of formal rules for determining what propositions are true or false given the assumption that some other set propositions is true or false. Probability theory provides a set of formal rules for determining the likelihood of a proposition being true given the likelihood of other propositions.

## 3.2 Random Variables

A **random variable** is a variable that can take on different values randomly. Random variables may be discrete or continuous.

## 3.3 Probability Distributions

A **probability distribution** is a description of how likely a random variable is to take on each of its possible states.

A probability distribution over discrete variables may be described using a **probability mass function** (PMF).

> The probability mass function maps from a state of a random variable to the probability of that random variable taking on that state.

Probability mass functions can act on many variables simultaneously. A probability distribution over many variables is know as a **join probability distribution**.

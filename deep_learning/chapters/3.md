# Probability and Information Theory

## Introduction

Probability Theory is a mathematical framework for representing uncertainty.

> It provides a means of quantifying uncertainty as well as axioms for deriving new uncertain statements.

In AI applications, probability theory is used in two major ways. First, the laws of probability tell us how systems should reason.

Second, we use probability and statistics to analyze behavior of proposed AI systems.

> While probability theory allows us to make uncertain statements and to reason in the presence of uncertainty, information theory enables us to quantify the amount of uncertainty in a probability distribution.

## 3.1 Why Probability?

Machine learning will always deal with uncertain quantities and sometimes stochastic (nondeterministic) quantities.

There are three possible sources of uncertainty:

1. Inherent stochasticity
1. Incomplete observability
1. Incomplete modeling

Probability related directly to the rates at which events occur is known as **frequentist probability**. Probability related to quantitative levels of certainty is know as **Bayesian probability**.

> Probability can be seen as the extension of logic to deal with uncertainty. Logic provides a set of formal rules for determining what propositions are true or false given the assumption that some other set propositions is true or false. Probability theory provides a set of formal rules for determining the likelihood of a proposition being true given the likelihood of other propositions.

## 3.2 Random Variables

A **random variable** is a variable that can take on different values randomly. Random variables may be discrete or continuous.

## 3.3 Probability Distributions

A **probability distribution** is a description of how likely a random variable is to take on each of its possible states.

A probability distribution over discrete variables may be described using a **probability mass function** (PMF).

> The probability mass function maps from a state of a random variable to the probability of that random variable taking on that state.

Probability mass functions can act on many variables simultaneously. A probability distribution over many variables is know as a **join probability distribution**.

When working with continuous random variables, we can describe probability distributions using a **probability density function** (PDF) rather than a PMF.

## 3.4 Marginal Probability

**Marginal probability** is the probability distribution over a subset of variables.

## 3.5 Conditional Probability

**Conditional probability** is the probability of some event given that some other event has occurred.

> It is important not to confuse conditional probability with computing what would happen if some action were undertaken. The conditional probability that a person is from Germany given that they speak German is quite high, but if a randomly selected person is taught to speak German, their country of origin does not change.

## 3.6 The Chain Rule of Conditional Probability

Any join probability distribution over many random variables can be decomposed into conditional distribution over one variable. This observation is known as the **chain** or **product rule**.

## 3.7 Independence and Conditional Independence

Random variables *x,y* are considered independent if their probability distribution can be expressed as a product of two factors, one involving only *x* and one involving only *y*.


## 3.8 Expectation, Variance and Covariance

The expected value (expectation) of some function *f(x)* with respect to a probability *P(x)* is the mean value that *f* takes on when *x* is drawn from *P*.

**Variance** gives a measure of how much the values of a function of a random variable *x* vary as we sample different values of *x* from its probability distribution.

The square root of the variance is known as the **standard deviation**.

**Covariance** gives some sense of how much two values are linearly related to one another.

> High absolute values of the covariance mean that the values change very much and are both far from their respective means at the same time. If the sign of the covariance is positive, then both variables tend to take on relatively high values simultaneously. If the sign of the covariance is negative, then one variable tends to take on a relatively high value at the times that the other takes on a relatively low value and vice versa.

Covariance is different from correlation which normalizes the contribution of each variable and only measures how much the variables are related.

> The notions of covariance and dependence are related, but are in fact distinct concepts. They are related because two variables that are independent have zero covariance, and two variables that have non-zero covariance are dependent. However, independence is a distinct property from covariance. For two variables to have zero covariance, there must be no linear dependence between them. Independence is a stronger requirement than zero covariance, because independence also excludes nonlinear relationships. It is possible for two variables to be dependent but have zero covariance.

## 3.9 Common Probability Distributions
